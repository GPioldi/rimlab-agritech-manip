# Development of a Control Software for Coordinating a Robotic Manipulator for Fruit Harvesting

> **Bachelor Thesis â€“ Department of Engineering & Architecture â€“ University of Parma**  
> Author: *Giuliano Pioldi* â€“ Academic year 2023â€‘24  
> Supervisors: **Prof.â€¯Ing.â€¯Ph.D.â€¯Darioâ€¯Lodiâ€¯Rizzini**, **Dr.â€¯Ing.â€¯Ph.D.â€¯Cand.â€¯Alessioâ€¯Saccuti**  
> Laboratory: **RIMLAB â€“ Robotics and Intelligent Machines Laboratory**

---

## Table of Contents
1. [Project Overview](#project-overview)
2. [Hardware Platform](#hardware-platform)
3. [Software Architecture](#software-architecture)
4. [Installation](#installation)
5. [QuickÂ Start](#quick-start)
6. [Repository Structure](#repository-structure)
7. [ImagesÂ &Â Media](#images--media)
8. [RoadmapÂ &Â FutureÂ Work](#roadmap--future-work)
9. [Howâ€¯toâ€¯Contribute](#how-to-contribute)
10. [Acknowledgments](#acknowledgments)
11. [License](#license)

---

## ProjectÂ Overview
This repository contains the **control software stack** developed for my experimental thesis *â€œDevelopment of a Control Software for Coordinating a Robotic Manipulator for Fruit Harvesting.â€*  
The goal is to **integrate, coordinate and control** a **UR10e** 6â€‘DOF manipulator mounted on a **ClearpathÂ Husky** unmanned ground vehicle (UGV) to autonomously detect, reach, grasp and pick tomato fruits in greenhouse and openâ€‘field scenarios.

### Key achievements
- **Unified launch pipeline** `launch/all_systems_tutti.py` that spawns *all* system components in simulationâ€¯&â€¯realÂ robots, including laboratory testâ€‘bed geometries and the Husky mobile base.  
- **Tomatoâ€‘picking state machine** (`src/tomato_pick/tomato_pick_node.cpp`) that  
  1. Detects candidate fruits using RGBâ€‘D perception;  
  2. Plans arm motion & approach trajectory;  
  3. Monitors **torque feedback** from UR10e internal current sensors to estimate resisting traction force;  
  4. Decides successful detachment and triggers retraction.  
- Modular ROSÂ packages (tested on **ROSÂ Noetic**, UbuntuÂ 20.04) and portable to ROSâ€¯2.  
- Extensive lab and field validation (see [ImagesÂ &Â Media](#images--media)).

---

## HardwareÂ Platform

| Subâ€‘System       | Model                                  | Function                                                       |
| ---------------- | -------------------------------------- | -------------------------------------------------------------- |
| **Manipulator**  | Universal Robots **UR10e**             | 6â€‘DOF arm, internal current sensors used for torque estimation |
| **Endâ€‘Effector** | Softâ€‘robotic gripper                   | Delicate tomato grasping                                       |
| **Mobile Base**  | **Clearpath HuskyÂ A200**               | Allâ€‘terrain UGV carrying the arm                               |
| **Perception**   | Intel **RealSenseâ€¯D435i** RGBâ€‘D camera | Fruit localisation & depth sensing                             |
| Â                 | **Ousterâ€‘64** 3â€‘DÂ LiDAR (optional)     | Environment mapping & navigation                               |

---

## SoftwareÂ Architecture
```
+--------------------------------------------------------------+
|                            ROSÂ Master                        |
+----------------------+---------------------+-----------------+
| NavigationÂ Stack     | PerceptionÂ Stack    | Manipulation    |
| (move_base / Nav2)   | (vision_msgs)       | (MoveIt!Â 2)     |
+----------------------+---------------------+-----------------+
|      HuskyÂ driver    | RealSenseÂ driver    | URÂ driver       |
+----------------------+---------------------+-----------------+
                        | torque_monitors  |
                        +------------------+
```
*FigureÂ â€“ Highâ€‘level ROS graph.*

- **Launch orchestration**: `launch/all_systems_tutti.py` â€” spawns Gazebo/MoveIt! simulation, RViz, real drivers and auxiliary nodes with one command.  
- **State machine**: implemented with **SMACC2â€‘style** pattern in C++ for ROS1 compatibility.  
- **Torque feedback**: raw joint currents â†’ estimated joint torques â†’ threshold logic to detect fruit detachment.

For a deepâ€‘dive, consult the thesis (see `docs/thesis/` when available).

---

## Installation
```bash
# 1. Clone
mkdir -p ~/agritech_ws/src && cd ~/agritech_ws/src
git clone https://github.com/GPioldi/rimlab-agritech-manip.git

# 2. Install dependencies (ROSÂ Noetic example)
cd ~/agritech_ws
rosdep install --from-paths src --ignore-src -r -y

# 3. Build
catkin_make    # or colcon build --symlink-install (ROS2)

# 4. Source workspace
source devel/setup.bash
```
> **Note:** For realâ€‘robot execution you will also need the official **URÂ ROSâ€¯Driver** and **Husky Base** packages from Clearpath.

---

## QuickÂ Start
### Simulation
```bash
roslaunch launch/all_systems_tutti.py sim:=true rviz:=true
```
### RealÂ Robot (lab)
```bash
ROS_MASTER_URI=http://husky:11311 \
roslaunch launch/all_systems_tutti.py sim:=false husky_hostname:=husky ur_ip:=192.168.131.10
```
### Tomatoâ€‘Picking Demo Only
```bash
rosrun tomato_pick tomato_pick_node
```

---

## RepositoryÂ Structure
Below is the **actual fileâ€‘tree** (excluding `.svn` metadata) extracted from the uploaded archive. This layout is kept inside the repository root `rimlab-agritech-manip/`.

```text
rimlab-agritech-manip/
â”œâ”€â”€ agritech_manip/                    # â†³ main ROS package
â”‚   â”œâ”€â”€ CMakeLists.txt
â”‚   â”œâ”€â”€ package.xml
â”‚   â”œâ”€â”€ Istruzioni.txt                 # quick Italian notes / TODOs
â”‚   â”œâ”€â”€ include/
â”‚   â”‚   â””â”€â”€ agritech_manip/
â”‚   â”‚       â”œâ”€â”€ robot_dispatcher.h
â”‚   â”‚       â”œâ”€â”€ static_object_tracker.h
â”‚   â”‚       â”œâ”€â”€ tomato_pick_node.h
â”‚   â”‚       â””â”€â”€ transform.h
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ robot_dispatcher.cpp
â”‚   â”‚   â”œâ”€â”€ static_object_tracker.cpp
â”‚   â”‚   â”œâ”€â”€ test_static_object_tracker.cpp
â”‚   â”‚   â”œâ”€â”€ tomato_pick.cpp            # library
â”‚   â”‚   â”œâ”€â”€ tomato_pick_node.cpp       # executable node (stateâ€‘machine)
â”‚   â”‚   â””â”€â”€ transform.cpp
â”‚   â”œâ”€â”€ launch/
â”‚   â”‚   â”œâ”€â”€ all_system.launch.py       # alternative setup
â”‚   â”‚   â”œâ”€â”€ all_system_husky.launch.py # ğŸï¸ field robot stack
â”‚   â”‚   â”œâ”€â”€ all_system_pal3.launch.py  # ğŸ  lab environment
â”‚   â”‚   â”œâ”€â”€ camera_only.launch.py
â”‚   â”‚   â”œâ”€â”€ tomato_pick_alone.launch.py
â”‚   â”‚   â”œâ”€â”€ tomato_pick_husky.launch.py
â”‚   â”‚   â”œâ”€â”€ my_realsense.launch.xml
â”‚   â”‚   â”œâ”€â”€ low_my_realsense.launch.xml
â”‚   â”‚   â””â”€â”€ realsense2_d405_before_update_20240629.launch.py
â”‚   â””â”€â”€ scene_geometry/
â”‚       â””â”€â”€ husky_manip_mobile.scene   # Gazebo object to load mobile base + arm
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ images/                        # â†’ README figures
â”‚   â”‚   â”œâ”€â”€ ManipulatorConfiguration.jpeg
â”‚   â”‚   â”œâ”€â”€ HuskyConfiguration.jpeg
â”‚   â”‚   â”œâ”€â”€ RobotParts.jpeg
â”‚   â”‚   â”œâ”€â”€ LabExperiment_1.jpeg
â”‚   â”‚   â”œâ”€â”€ LabExperiment_2.jpeg
â”‚   â”‚   â””â”€â”€ OnFieldExperiment.jpeg
â”‚   â””â”€â”€ videos/                        # (to be filled)
â”œâ”€â”€ LICENSE                            # MIT
â””â”€â”€ README.md                          # this file
```
*If you later split code into more ROS packages (e.g. `tomato_pick`), please update this list.*

---

## ImagesÂ &Â Media
| Image | Caption |
|-------|---------|
| ![Manipulator configuration](docs/images/ManipulatorConfiguration.jpeg) | **Bench setâ€‘up of the UR10e manipulator.** 6â€‘DOF arm clamped on a rigid frame inside RIMLAB for kinematic calibration and controller tuning. |
| ![Husky configuration](docs/images/HuskyConfiguration.jpeg) | **UR10e on Husky UGV.** Complete mobile manipulation platform; note the RealSenseâ€¯D435i on the wrist and the soft gripper. |
| ![Robot parts](docs/images/RobotParts.jpeg) | **Joint and link naming scheme.** Helpful when referencing torque or position feedback in code and during troubleshooting. |
| ![Lab experimentÂ 1](docs/images/LabExperiment_1.jpeg) | **Lab trial â€“ approach phase.** The arm aligns the endâ€‘effector with a ripe tomato detected by the vision stack. |
| ![Lab experimentÂ 2](docs/images/LabExperiment_2.jpeg) | **Lab trial â€“ detachment detection.** Snapshot taken as the torque threshold indicates successful fruit pick. |
| ![Onâ€‘field experiment](docs/images/OnFieldExperiment.jpeg) | **First onâ€‘field test.** Husky navigates a tomato row in an outdoor plot; the manipulator harvests under natural lighting. |

> **Video footage** will be uploaded in `docs/videos/` and embedded in the Wiki.

---

## RoadmapÂ &Â FutureÂ Work
| Status | Item                             | Description                                                                                                                 |
| ------ | -------------------------------- | --------------------------------------------------------------------------------------------------------------------------- |
| ğŸ”„Â WIP | **Extensive field trials**       | Benchmark performance in real greenhouse rows under varying lighting, canopy density and fruitâ€‘ripeness conditions.        |
| ğŸš€     | **Torqueâ€‘threshold autoâ€‘tuning** | Online adaptation of detachment thresholds to minimise missed picks and stem damage.                                        |
| â±ï¸     | **Cycleâ€‘time optimisation**      | Parallelise perception & motion planning to cut pickâ€‘andâ€‘place time belowÂ 5â€¯s per fruit.                                    |
| ğŸŒ     | **SLAMÂ + autonomous navigation** | Rowâ€‘coverage planning with LiDARÂ & RGBâ€‘D fusion (Nav2 integration).                                                         |
| ğŸ“     | **Multiâ€‘fruit generalisation**   | Extend perception & gripper parameters to strawberries & bell peppers.                                                      |
| ğŸ“¦     | **Dataset release**              | Publish RGBâ€‘D + jointâ€‘torque logs under CCâ€‘BY for community benchmarking.                                                   |
| ğŸ’¬     | **Community ideas welcome!**     | **Any suggestion?Â Write me!Â ğŸ˜Š** Open an issue or ping me onÂ GitHub â€” we love feedback!                                     |

---

## HowÂ toÂ Contribute
1. **Fork** the repo and create your branch: `git checkout -b feature/foo_bar`  
2. **Commit** your changes: `git commit -am 'Add some foo_bar'`  
3. **Push** to the branch: `git push origin feature/foo_bar`  
4. Create a **Pull Request** with a concise description.  

Please run `catkin_lint` and `clang-format` before submitting a PR.

---

## Acknowledgments
This project has been made possible thanks to the invaluable support of **RIMLAB â€“ Robotics and Intelligent Machines Laboratory** (University of Parma) and the mentorship of **Prof.â€¯Ing.Â Ph.D.Â DarioÂ Lodiâ€¯Rizzini** and **Dr.Â Ing.Â Ph.D.Â Cand.Â AlessioÂ Saccuti**.  
Additional thanks go to colleagues who provided hardware assembly help, debugging assistance and fruitful discussions.

---

## License
Distributed under the **MIT License**. See [`LICENSE`](LICENSE) for more information.

---
